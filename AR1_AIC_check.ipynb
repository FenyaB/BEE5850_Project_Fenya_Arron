{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3b162f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fenya\\AppData\\Local\\Temp\\ipykernel_5004\\2640477137.py:23: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  energy_data.index = pd.to_datetime(energy_data.index, format='mixed')\n",
      "C:\\Users\\fenya\\AppData\\Local\\Temp\\ipykernel_5004\\2640477137.py:33: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  weather_data1.index = pd.to_datetime(weather_data1.index, format='mixed')\n",
      "C:\\Users\\fenya\\AppData\\Local\\Temp\\ipykernel_5004\\2640477137.py:38: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  weather_data2.index = pd.to_datetime(weather_data2.index, format='mixed')\n",
      "C:\\Users\\fenya\\AppData\\Local\\Temp\\ipykernel_5004\\2640477137.py:43: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  weather_data3.index = pd.to_datetime(weather_data3.index, format='mixed')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "from scipy.optimize import Bounds\n",
    "from scipy.stats import poisson\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "import matplotlib.dates as mdates\n",
    "# import mpl_scatter_density # adds projection='scatter_density'\n",
    "\n",
    "# os.chdir('BEE5850_Project_Fenya_Arron')\n",
    "data_dir = os.path.join(\"data\", \"EnergyUsageClassroomsAll.csv\")\n",
    "energy_data = pd.read_csv(data_dir)\n",
    "energy_data[['Time','Zone']]= energy_data['ts'].str.split(' ', n=1, expand=True)\n",
    "energy_data = energy_data.set_index('Time')\n",
    "energy_data.index = pd.to_datetime(energy_data.index, format='mixed')\n",
    "\n",
    "# Leaving out 2024 to use as testing data\n",
    "# training_years = [(energy_data.index[i].year == 2022) | (energy_data.index[i].year == 2023) for i in range(energy_data.shape[0])]\n",
    "# energy_data = energy_data[(training_years)]\n",
    "\n",
    "data_dir = os.path.join(\"data\", \"2022WeatherHistorical.csv\")\n",
    "weather_data1 = pd.read_csv(data_dir)\n",
    "weather_data1[['Time','Zone']]= weather_data1['Timestamp'].str.split(' ', n=1, expand=True)\n",
    "weather_data1 = weather_data1.set_index('Time')\n",
    "weather_data1.index = pd.to_datetime(weather_data1.index, format='mixed')\n",
    "data_dir = os.path.join(\"data\", \"2023WeatherHistorical.csv\")\n",
    "weather_data2 = pd.read_csv(data_dir)\n",
    "weather_data2[['Time','Zone']]= weather_data2['Timestamp'].str.split(' ', n=1, expand=True)\n",
    "weather_data2 = weather_data2.set_index('Time')\n",
    "weather_data2.index = pd.to_datetime(weather_data2.index, format='mixed')\n",
    "data_dir = os.path.join(\"data\", \"WeatherHistorical.csv\")\n",
    "weather_data3 = pd.read_csv(data_dir)\n",
    "weather_data3[['Time','Zone']]= weather_data3['Timestamp'].str.split(' ', n=1, expand=True)\n",
    "weather_data3 = weather_data3.set_index('Time')\n",
    "weather_data3.index = pd.to_datetime(weather_data3.index, format='mixed')\n",
    "weather_data = pd.concat([weather_data1, weather_data2, weather_data3])\n",
    "weather_data = weather_data.drop_duplicates()\n",
    "\n",
    "\n",
    "col = 'Ithaca, NY, United States Humidity'\n",
    "weather_data[col] = (weather_data[col] - weather_data[col].mean())/weather_data[col].std()\n",
    "\n",
    "col = 'Ithaca, NY, United States Temp'\n",
    "weather_data[col] = (weather_data[col] - weather_data[col].mean())/weather_data[col].std()\n",
    "\n",
    "weather_data = weather_data.drop(weather_data.index.difference(energy_data.index))\n",
    "energy_data = energy_data.drop(energy_data.index.difference(weather_data.index))\n",
    "energy_data = energy_data.drop(['ts','Zone'], axis=1)\n",
    "\n",
    "data_dir = os.path.join(\"data\", \"Cornell_Classroom_Building_Square_Footage.xlsx - Sheet1.csv\")\n",
    "square_footage = pd.read_csv(data_dir)\n",
    "square_footage['Building Name'] = square_footage['Building Name'].replace(\" \", \"\")\n",
    "square_footage['Building Name'] = [square_footage['Building Name'][i].replace(\" \", \"\") for i in range(square_footage.shape[0])]\n",
    "square_footage.index = square_footage['Building Name']\n",
    "\n",
    "energy_data = energy_data.drop(columns=['KimballHall','StatlerHall','VetMedicalCenter','PlantScience','KlarmanHall','GatesHall','MyronTaylorHall','GoldwinSmithHall','UrisHall','StimsonHall','MarthaVanRensselaerComplex','SageHall'])\n",
    "# Calculate z score\n",
    "for bdg in energy_data.columns:\n",
    "    energy_data[bdg] = (energy_data[bdg] -energy_data[bdg].mean())/energy_data[bdg].std()\n",
    "    \n",
    "np.isnan(weather_data['Ithaca, NY, United States Humidity']).any()\n",
    "y = energy_data.transpose().to_numpy().reshape(-1, 1)\n",
    "nan_data = (np.isnan(y))\n",
    "y =y[~nan_data].reshape(-1, 1)  \n",
    "\n",
    "\n",
    "humid = np.tile(np.array(weather_data.iloc[:,[3]]),(energy_data.shape[1],1)).reshape(-1, 1)[~nan_data].reshape(-1, 1)  \n",
    "temp = np.tile(np.array(weather_data.iloc[:,[4]]),(energy_data.shape[1],1)).reshape(-1, 1)[~nan_data].reshape(-1, 1) \n",
    "# sites = np.tile(df.columns, df.shape[0])\n",
    "\n",
    "# x_lat =x_lat.reshape(-1, 1)[~nan_data].reshape(-1, 1)\n",
    "# x_lon =x_lon.reshape(-1, 1)[~nan_data].reshape(-1, 1)\n",
    "# dates = energy_data.index\n",
    "dates = np.tile(energy_data.index, energy_data.shape[1])\n",
    "months = np.zeros(len(dates))\n",
    "hours = np.zeros(len(dates))\n",
    "# len(dates)\n",
    "# Store months for stratification \n",
    "for i in range(dates.shape[0]):\n",
    "    ts = pd.Timestamp(dates[i])\n",
    "    months[i]=ts.month\n",
    "\n",
    "hours = np.zeros(dates.shape[0])\n",
    "for i in range(dates.shape[0]):\n",
    "    ts = pd.Timestamp(dates[i])\n",
    "    hours[i]=ts.hour\n",
    "\n",
    "\n",
    "months = months.reshape(-1, 1)[~nan_data].reshape(-1, 1)  \n",
    "hours = hours.reshape(-1, 1)[~nan_data].reshape(-1, 1)  \n",
    "X = np.concatenate((humid, temp), axis=1)\n",
    "# pd.Series(y.reshape(-1,))[70000:70300].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ea7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to be the name of the file that has the parameters for the fitted AR1 model\n",
    "θ_mle = pd.read_csv('params_classrooms_2022_2024_hour_month_withAR1_ZScore_May2_Fenya.csv')\n",
    "θ_mle = θ_mle.drop(['Unnamed: 0'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f466dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def electricity_linear_model(params, X):\n",
    "    μ =  params[0] + X[:,0]* params[1] + X[:,1]* params[2] + params[3]*np.cos((params[4]*hours).reshape(-1,) + params[5]) + params[6]*np.cos((params[7]*months).reshape(-1,) + params[8])\n",
    "    return μ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1de175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elec_loglik(params, X, y):\n",
    "    ρ = params[-1]\n",
    "    σ = params[-2]\n",
    "    elec_sim = electricity_linear_model(params, X)\n",
    "    residuals = (y - np.array(elec_sim).reshape(-1,1))\n",
    "    # ll = np.sum(norm.logpdf(gmsl_data, loc=y, scale=np.sqrt(σ**2+gmsl_error**2)))  # compute log-likelihood\n",
    "    T = len(y)\n",
    "    ll = 0  # initialize log-likelihood counter\n",
    "    for t in range(len(elec_sim)):\n",
    "        if t == 0:\n",
    "            ll += norm.logpdf(residuals[0], loc=0, scale=np.sqrt(σ**2 / (1 - ρ**2)))\n",
    "        else:\n",
    "            resid_wn = residuals[t] - ρ * residuals[t-1]\n",
    "            ll += norm.logpdf(resid_wn, loc=0, scale=np.sqrt(σ**2))\n",
    "\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e81c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_AR1 = -2*(elec_loglik(θ_mle, X, y) - len(θ_mle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bdf171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([346360.90040828])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIC_AR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0744e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def electricity_demand_model(params, X, y):\n",
    "    σ = params[-1]\n",
    "    μ = electricity_linear_model(params, X)\n",
    "    ll = np.sum(norm.logpdf(pd.Series(y.reshape(-1,)), μ, scale=σ))  # compute log-likelihood\n",
    "    return ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29f6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [-10.0, -10.0, -10.0, -10.0, -100.0, 0, -100.0, -100.0, 0, 0.0001]\n",
    "ub = [10.0, 10.0, 10.0, 10.0, 100.0, 2*math.pi, 100.0, 1000.0, 2*math.pi, 10.0]\n",
    "init = [0.1, 0.1, 0.1, 0.01, 0.1, 0.1, 0.1,0.1, 0.1, 0.1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5625c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(lambda θ: -electricity_demand_model(θ, X, y), init, bounds=list(zip(lb, ub)))\n",
    "θ_mle = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62feb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_IID = -2*(electricity_demand_model(θ_mle, X, y) - len(θ_mle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7bb50e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(645290.328060484)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIC_IID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
